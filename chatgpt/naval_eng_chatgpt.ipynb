{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBrain():\n",
    "\n",
    "    def __init__(self, templ='chat', model='gpt-3.5-turbo-0125', parse=\"str\"):\n",
    "\n",
    "        self.templ = templ\n",
    "        self.model = model\n",
    "        self.parse = parse\n",
    "        \n",
    "        self._set_llm()\n",
    "\n",
    "    def _set_prompt(self):\n",
    "\n",
    "        if self.templ == 'chat':\n",
    "            self.prompt = ChatPromptTemplate.from_messages([\n",
    "                    (\"system\", \"{system}\"),\n",
    "                    (\"user\", \"{input}\")\n",
    "                ])\n",
    "            \n",
    "    def _set_model(self):\n",
    "\n",
    "        self.llm = ChatOpenAI(model=self.model)\n",
    "\n",
    "    def _set_parser(self):\n",
    "\n",
    "        if self.parse == 'str':\n",
    "            self.parser = StrOutputParser() \n",
    "    \n",
    "    def _set_llm(self):\n",
    "\n",
    "        self._set_prompt()\n",
    "        self._set_model()\n",
    "        self._set_parser()\n",
    "\n",
    "        self.model = self.prompt | self.llm | self.parser\n",
    "\n",
    "    def invoke(self, system, input):\n",
    "\n",
    "        return self.model.invoke({\"system\":system,\"input\": input})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_f_string(specify, data, is_list):\n",
    "\n",
    "    general = \"You are a helpful naval engineer whose job is to summarise data extracted from the management \\\n",
    "    action plan of the ship. The specific situation of the ship is the following:\"\n",
    "    \n",
    "    summary = \"You make a brief summary of the data, provided by the user below. The style of the text should \\\n",
    "    be in accordance with your role. The responce, should contain the minimum number of sentences, which they \\\n",
    "    should be as brief as possible.\\n\\n\"\n",
    "    \n",
    "    if is_list:\n",
    "        list_data = \"\\nThe data that are provided by the user are given as a list of features.\\n\"\n",
    "    else:\n",
    "        list_data = \"\\nThe data that are provided by the user are given as a dictionary of key-value pairs, \\\n",
    "        with keys and values representing the features and their values respectively.\\n\"\n",
    "    \n",
    "    return f\"{general} {specify} {summary} {list_data} {data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(specific, params, data=None):\n",
    "\n",
    "    if data == None:\n",
    "        is_list = True\n",
    "        data = params\n",
    "    else:\n",
    "        is_list = False\n",
    "        data = {k:v for (k, v) in zip(params, data)}\n",
    "    \n",
    "    brain = ChatBrain()\n",
    "    system=create_f_string(specific, data, is_list)\n",
    "    answer = brain.invoke(system, data)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ship is currently operating at a speed of 15 knots, exceeding the speed limit of 10 knots. The fuel burn rate is at 14,000 gallons, surpassing the limit of 10,000 gallons.\n"
     ]
    }
   ],
   "source": [
    "# 6 > col 3\n",
    "spec = \"The ship operates outside its usual operating profile.\"\n",
    "params = [\"speed\", \"fuel_burn\", \"speed_limit\", \"fuel_burn_limit\"]\n",
    "data = [\"15\", \"14000\", \"10\", \"10000\"]\n",
    "\n",
    "print(call_llm(spec, params, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ship is scheduled for Dry Docking and Inspection on the 13th of April 2021.\n"
     ]
    }
   ],
   "source": [
    "# 8 > row 1\n",
    "spec = \"The ship needs maintenance. The timing of different operational \\\n",
    "        activities is the parameter of interest that needs to be mentioned.\"\n",
    "params = [\"type_of_maintenance\", \"timing\"] \n",
    "data = [\"Dry Docking and Inspection\", \"13-04-2021\"] \n",
    "\n",
    "print(call_llm(spec, params, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 > row 2\n",
    "spec = \"The ship needs maintenance. In-water cleaning takes place.\"\n",
    "params = [\"timing_btw_dry_dock\", \"treatment/cleaning_conducted\", \"operational_procedures\",\n",
    "          \"chemicals_used\", \"discharge_standards\", \"areas\"]\n",
    "data = []\n",
    "\n",
    "print(call_llm(spec, params, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat_env_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
